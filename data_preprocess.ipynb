{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKyxmwsNiWry"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ECE661_Project/CheXpert/train.csv')\n",
        "df = df[df['Frontal/Lateral'] == 'Frontal']\n",
        "df = df[df['AP/PA'] == 'AP']\n",
        "df"
      ],
      "metadata": {
        "id": "qti3sGYEid2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display image count per pathology\n",
        "feature_cols = df.columns[5:]\n",
        "counts = df[feature_cols].eq(1.0).sum()\n",
        "counts"
      ],
      "metadata": {
        "id": "EqB_JgyhjAai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_cols = ['Cardiomegaly', 'Pleural Effusion', 'Pneumothorax']\n",
        "mask = df[target_cols].eq(1.0).any(axis=1)\n",
        "\n",
        "df_3class = df.loc[mask].reset_index(drop=True)[(list(df.columns[:5]) + target_cols)]\n",
        "df_3class.fillna(0, inplace=True)\n",
        "print(f\"Kept {len(df_3class)} of {len(df)} rows.\")\n",
        "df_3class"
      ],
      "metadata": {
        "id": "ovfiDJ2ylMIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_3class.to_csv('train_label.csv', index=False)"
      ],
      "metadata": {
        "id": "414tenL-DVA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qmHyphdkVF4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ECE661_Project/train_label.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "UVqd_a88FL9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving 60,000 images per batch due to RAM limit\n",
        "paths = df[\"Path\"]\n",
        "start_time = time.time()\n",
        "print(f'number of images to save: {len(paths)}')\n",
        "image_arrays = []\n",
        "id_array = []\n",
        "ct = 60000\n",
        "for p in paths[60000:]:\n",
        "    p = '/kaggle/input/chexpert/train' + p.split('train')[-1]\n",
        "    try:\n",
        "        with Image.open(p) as img:\n",
        "          img = img.convert(\"RGB\")\n",
        "          arr = np.array(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: skipping {p!r} due to error: {e}\")\n",
        "        continue\n",
        "\n",
        "    image_arrays.append(arr)\n",
        "    id_array.append(p.split('train/')[-1].split('.')[0])\n",
        "    ct += 1\n",
        "    if ct % 20000 == 0:\n",
        "      image_arrays = np.array(image_arrays)\n",
        "      id_array = np.array(id_array)\n",
        "      np.savez(f\"image_train{ct}_1.npz\", image=image_arrays, id = id_array)\n",
        "      print(f\"Saved first {ct} images, image size: {image_arrays.shape}\")\n",
        "      image_arrays = []\n",
        "      id_array = []\n",
        "\n",
        "image_arrays = np.array(image_arrays)\n",
        "id_array = np.array(id_array)\n",
        "np.savez(f\"image_train{ct}_1.npz\", image=image_arrays, id = id_array)"
      ],
      "metadata": {
        "id": "HS_VE3A9FL_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YVSRMXCS8PMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load image for inspection\n",
        "np.load('/content/drive/MyDrive/ECE661_Project/image_train15.npz')['id'][3]"
      ],
      "metadata": {
        "id": "fJoYFKfcSwHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1 = np.load('/content/drive/MyDrive/ECE661_Project/CheXpert-v1.0-small/image_train20000.npz')\n",
        "dataset2= np.load('/content/drive/MyDrive/ECE661_Project/CheXpert-v1.0-small/image_train40000.npz')\n",
        "dataset3 = np.load('/content/drive/MyDrive/ECE661_Project/CheXpert-v1.0-small/image_train49815.npz')\n",
        "dataset4 = np.load('/content/drive/MyDrive/ECE661_Project/CheXpert-v1.0-small/image_train80000.npz')\n",
        "dataset5 = np.load('/content/drive/MyDrive/ECE661_Project/CheXpert-v1.0-small/image_train83937.npz')\n",
        "ids = [dataset['id'] for dataset in [dataset1, dataset2, dataset3, dataset4, dataset5]]\n",
        "ids = np.concatenate(ids)"
      ],
      "metadata": {
        "id": "tkyKDyY6CKZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZsPr-NKqCKhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dot over the last axis to apply weights â†’ result is (N, H, W)\n",
        "rgb_float = images.astype(np.float32) / 255.0\n",
        "weights = np.array([0.2989, 0.5870, 0.1140], dtype=rgb_float.dtype) #convert to grayscale using Luma Coefficients\n",
        "gray_float = np.tensordot(rgb_float, weights, axes=([-1], [0]))\n",
        "grayscale_uint8 = (gray_float * 255).astype(np.uint8)\n",
        "\n",
        "np.save(\"/content/drive/MyDrive/ECE661_Project/CheXpert-v1.0-small/train_image_greyscale.npy\", grayscale_uint8)\n",
        "loaded = np.load(\"/content/drive/MyDrive/ECE661_Project/CheXpert-v1.0-small/train_image_greyscale.npy\")"
      ],
      "metadata": {
        "id": "k4FOv4Qs-viR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iktyAe2xFe4b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}